1、以cluster模式的PushConsumer为例：
	启动时，会根据topic先从nameser获取获取topic对应的broker address 以及对应的message queue消息队列集合视图，在rmq中，topic-broker-queueId确定一条唯一的消
息队列,然后为每条消息队列创建一个PullRequest实例，该pullRequst是实现consumer端主动向broker拉取消息的关键。
	刚刚说到，consumer客户端会为每一条消息队列创建一个PullRequest,然后放入List<PullRequest>,也即PullRequest集合，然后遍历PullRequest集合，在放入一个由
PullMessageService类管理的pullRequestQueue，拉取消息的生产消费队列；PullMessageService类是拉取消息的线程抽象模型，也就是使用同一个MQClientInstance实例的所有队
列，都会由该线程主动向broker拉取消息，以后会专门说到MQClientInstance类，现在先不讲。
	PullRequest里面有一个属性nextOffset，表明希望重broker拉取的消息的逻辑位移，broker根据nextOffset,会返回一些列内容，该内容在客户端反序列化以后，构造成
PullResult实例，该对象有返回的消息集合以及下一次获取消息的位移nextBeginOffset，然后设置回PullRequest.nextOffset，接着将拉取回来的消息交给ConsumeMessageService
消费消息线程抽象类去异步处理获取回来的消息，执行用户的消费逻辑；然后在将PullRequest复用，在次放进PullMessageService类管理的pullRequestQueue，从而达到不停拉取消
息的效果。



2、PullRequest第一次创建时nextOffset的设置情况：
	如果是pull模式，则重0开始，即重broker 的最小offset开始消费。
	如果是push模式，如果设置的ConsumeFromWhere是一下几种模式：CONSUME_FROM_LAST_OFFSET_AND_FROM_MIN_WHEN_BOOT_FIRST、CONSUME_FROM_MIN_OFFSET、
CONSUME_FROM_MAX_OFFSET、CONSUME_FROM_LAST_OFFSET等模式，则走一下处理：
	先从BrokerController.ConsumerOffsetManager.offsetTable 缓存，根据topic@group 获取最新可消费的logic offset；如果查询异常，或不存在，则返回-1，这时，在通
过ConsumeQueue获取max logic offset，如果还查询不到则返回0。这里有可能会有一种情况出现，就是当broker启动时，由于ConsumeQueue是异步重新加载恢复的，这时后可能
consumer端会向该broker发起消费请求，但ConsumeQueue还没加载完成，导致返回0，这时，consumer端会可能从头消费一遍该消息队列。



3、Cluster 模式，PushConsumer 拉取消息然后commit消息流程：
	公共流程：
	首先，对批量拉取回来的消息进行反序列化，然后在过滤掉不包含本consumer端所指定tag的消息。
	然后，拉取回来的消息，根据offset，进行排序。接着将详细委托ConsumeMessageService类进行异步消费
	3.1并发消费(ConsumeMessageConcurrentlyService)：
		消息会更具客户端设置的consumeBatchSize(默认为1)，并发消费批量的消息，执行用户自定义的逻辑后，统计返回消息的成功数，然后将不成功的消息重新发送回
broker，放入消息头，使消息可以重新消费，发送消息明确成功以后，会返回成功，当客户单收到明确成功以后，会认为该消息消费成功，然后在将消费失败，并且发送broker失败
的消息延时消费，根据消费成功的消息，算出最小可commit的消息位移，最后在想本地队列commit缓存更新最新可提交的offset，在由定时器定时向broker发出commit请求。
		这里详细分析一下上述内容，以及我们的使用技巧；这里，根据我们的假设的场景，在结合分析。
		例如，根据PullRequest，我们一次拉回来6条消息,然后将拉取回来的消息放入一个ProcessQueue.msgTreeMap，这是一颗红黑树，按照拉取回来的消息的offset进
行排序，用读写锁保证并发安全，这里我们根据offset排一下消息的序列[1,2,3,4,5,6]，则ProcessQueue.queueOffsetMax = 6;consumeBatchSize的值我们设置了3，也就是说,分别
有两个线程,分别Thread1消费[1,2,3] 和Thread2消费[4,5,6]，接下来就是我们客户端如何使用分析，在Thread1中，我们遍历消费（1,2,3）这三条消息，并执行我们客户端的逻辑
，假如，我们在执行第一条消息成功了，ConsumeConcurrentlyContext.ackIndex该属性应该+1变成1，该属性的意义是前ackIndex条消息都是消费成功的，然后执行第二条消息时由
于用户代码失败了，这里失败分两个情况，第一个是直接抛出异常，我们没有捕捉；另外一种就是我们自己明确返回CONSUME_SUCCESS，如果我们设置了ackIndex，两种情况其实是一
样的。返回以后，ackIndex=1表明消息组（1,2,3),只有第一条消息是消费成功的，然后将剩下两条消息重新向broker发送，假如，消息2发送失败，则将该消息放入延时消费集合，
用定时器延时消费，而第三条消息发送成功了，则表明对于该消费者来说，已经消费成功。然后，将消费成功的消息重msgTreeMap移除，最后根据msgTreeMap返回commit offset的值
为2，只要消息2没有被延时消费成功，即使Thread2已经成功消费了消息(4,5,6)，最大可commit的offset依然是小于2，如果消息延时消费成功以后，则max commit offset则为7，说
明offset小于7的消息都已近消费成功。
